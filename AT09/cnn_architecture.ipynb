{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo a Arquitetura da CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Extracao de características](extracao_caracteristicas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aquisição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "y_train = utils.to_categorical(y_train) #8 -> 0 0 0 0 0 0 0 0 1 0\n",
    "y_test = utils.to_categorical(y_test) #3 -> 0 0 0 1 0 0 0 0 0 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Arquitetura da CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Arquitetura CNN](cnn_arquitetura_basica.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando a CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#Camada de convolução\n",
    "classifier.add(Convolution2D(32, kernel_size=(3,3), input_shape = (28, 28,1), activation = 'relu', padding='same', name = 'conv_1'))\n",
    "\n",
    "#Camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='same', name = 'pool_1'))\n",
    "\n",
    "#Segunda camada convolucional\n",
    "classifier.add(Convolution2D(64, kernel_size=(3,3), activation = 'relu', padding='same', name = 'conv_2'))\n",
    "\n",
    "#Dropout\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "#Segunda camada de pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name = 'pool_2'))\n",
    "\n",
    "\n",
    "#Vetorizando os mapas de características do último pooling (camada de entrada)\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Dropout\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "#Camada totalmente conectada ou oculta\n",
    "classifier.add(Dense(activation='relu', units=128, name = 'dense_1'))\n",
    "\n",
    "\n",
    "#Camada de saída\n",
    "classifier.add(Dense(activation='softmax', units=10,  name = 'classification'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Atividade (2.5):$  Classificando um conjunto de imagens de animais (gato, cachorro e panda)\n",
    "1. Aquisição das imagens através do dataset: https://www.kaggle.com/ashishsaxena2209/animal-image-datasetdog-cat-and-panda\n",
    "2. Pré-processamento: Redimensione a imagem do dataset para 64 × 64 pixels, e certifique-se de que tenham os três canais (RGB). As imagens nas quais o modelo deve ser treinado devem ser pré-processadas para que seus valores variem de [0,1], portanto, você deve garantir que suas imagens também estejam no mesmo intervalo. As labels devem ser criadas e transformadas em dados categóricos e não esqueçam de embaralhar as amostras de modo que a label também seja embaralhada na mesma sequência. Dica: função load_img do keras.preprocessing.image e utilizar 80% das amostras para treino e 20% para teste;\n",
    "3. Adaptar a arquitetura apresentada no tutorial para o novo dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
